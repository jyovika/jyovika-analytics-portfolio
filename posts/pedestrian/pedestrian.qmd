---
title: "How Busy Are Melbourneâ€™s CBD Crossings? A Statistical Deep Dive"
description: "Modelling pedestrian flows at Southern Cross, Flinders Street, and QV Melbourne using probability models, bootstrapping, and confidence intervals."
author: "Jyovika Aswale"
date: 2 December 2025
categories: [R, Statistics, Pedestrian counts, Melbourne]
format:
  html:
    toc: true
    toc-location: left
    code-summary: "Show code"
    df-print: default
---

::: {.callout-note collapse="true" icon="people" title="Collaboration & Original Assignment"}
This analysis began as a group assignment for our Statistical Thinking unit, completed together with **Sia Chawla** and **Siddhi Jadhav**.  
The core data wrangling, modelling, and statistical code were developed collaboratively.

This blog post is my own adapted version for my analytics portfolio, Iâ€™ve rewritten the narrative, added explanations, and restructured the presentation for a broader readership, but the underlying work is **not solely my own**.

You can find the original group repository here:  
ðŸ‘‰ **Original Assignment GitHub Repo:** <https://github.com/jyovika/Pedestrian_Crossings_Data_Analysis> 
:::

## Introduction 

The centre of Melbourne is full of movement and energy. Every day thousands of people pass through places like Southern Cross, Flinders Street, and QV Melbourne. At first glance it feels chaotic. Underneath that movement however is a pattern. I wanted to understand those patterns and tell a story about how these three locations behave.

I approached this like a real analytics problem. Start with descriptive exploration. Fit distributions that reflect the character of each location. Estimate meaningful quantities for planning and design. Compare sites in a way that answers the practical questions that planners and marketers actually care about.
By the end of the analysis, these three crossings no longer felt like random busy spots on a map. They felt like distinct personalities with their own rhythms and their own commercial and operational implications.

```{r, setup, echo=FALSE}
#| label: setup
#| include: false
#| message: false
#| warning: false
knitr::opts_chunk$set(
fig.align = "center",
fig.width = 8,
fig.height = 5,
dpi = 150,
echo = TRUE,
warning = FALSE,
message = FALSE
)

library(boot)
library(MASS)
library(tidyverse)
library(knitr)
library(kableExtra)
library(broom)
library(purrr)
library(scales)

set.seed(355435)

cross_cols <- c(
"Flinders Street" = "#766153",
"QV Melbourne" = "#718f94",
"Southern Cross"  = "#717744")

```

```{r,cleaning-and-loading-data, echo=FALSE}
pedestrian_df <- read.csv(here::here("data/pedestrian/pedestrians.csv"))

pedestrian_long <- pedestrian_df %>%
  mutate(obs = row_number()) %>%
  pivot_longer(-obs, names_to = "crossing", values_to = "count") %>%
  mutate(crossing = recode(crossing,
                           "flinders_street" = "Flinders Street",
                           "qv_melbourne"    = "QV Melbourne",
                           "southern_cross"  = "Southern Cross")) %>%
  mutate(crossing = factor(
    crossing,
    levels = c("Southern Cross", "Flinders Street", "QV Melbourne")))
```

## First Impressions Through Visuals

To get a feel for how each location behaves, I plotted boxplots and density curves. These gave a surprisingly clear first impression.

::: columns
::: {.column width="50%"}

```{r, echo=FALSE}
#| label: fig-boxplot
#| fig-cap: "Pedestrian counts by crossing."
ggplot(pedestrian_long, aes(x = crossing, y = count, fill = crossing)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.8) +
  scale_fill_manual(values = cross_cols) +
  labs(x = NULL, y = "Count per interval") +
  theme_minimal() +
  theme(legend.position = "none")

```

:::
::: {.column width="50%"}

```{r, echo=FALSE}
#| label: fig-density
#| fig-cap: "Distribution of pedestrian counts by crossing."
ggplot(pedestrian_long, aes(x = count, fill = crossing)) +
  geom_density(alpha = 0.35) +
  facet_wrap(~ crossing, scales = "fixed") +
  scale_fill_manual(values = cross_cols) +
  labs(x = "Count", y = "Density") +
  theme_minimal() +
  theme(legend.position = "none")
```

:::
:::

QV Melbourne clearly carries the heaviest flow. Southern Cross and Flinders Street sit closer together although Flinders has slightly lower typical values. All three distributions show right skew which tells us they have occasional high traffic bursts.

The summary statistics confirm these observations.
```{r, echo=FALSE}
#| label: tbl-crossing-summary
#| tbl-cap: "Descriptive statistics for pedestrian counts at each crossing."
pedestrian_long %>%
  group_by(crossing) %>%
  summarise(
    n      = n(),
    mean   = mean(count),
    median = median(count),
    sd     = sd(count),
    min    = min(count),
    max    = max(count),
    iqr    = IQR(count),
    .groups = "drop"
  ) %>%
  kable(
    digits = 1,
    col.names = c("Crossing", "n", "Mean", "Median", "SD", "Min", "Max", "IQR")
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE
  ) %>%
  row_spec(0, bold = TRUE, color = "#FFFFFF", background = "#598392") %>%
  column_spec(1, bold = TRUE, color = "#004D40")
```

At this stage it already felt like QV Melbourne was in a different league. It is not just busy. It is volatile. That volatility becomes important once we start modelling.

## Choosing Statistical Models That Fit

To describe each crossing in a way that is useful for prediction and design, I fit Normal, Lognormal, and Gamma models. I did this for each site and compared the fits through likelihood values and visual diagnostics.

```{r, echo=FALSE}
#| label: tbl-mle
#| tbl-cap: "Maximum-likelihood estimates for Normal, Lognormal and Gamma models across the three crossings."

# Southern Cross
sc <- pedestrian_df$southern_cross
fit_sc_norm  <- fitdistr(sc, "normal")
fit_sc_logn  <- fitdistr(sc, "lognormal")
fit_sc_gamma <- fitdistr(sc, "gamma")   

sc_models <- tibble(
  crossing = "Southern Cross",
  model    = c("normal","lognormal","gamma"),
  logLik   = c(logLik(fit_sc_norm)[1],  logLik(fit_sc_logn)[1],  logLik(fit_sc_gamma)[1]),
  AIC      = c(AIC(fit_sc_norm),        AIC(fit_sc_logn),        AIC(fit_sc_gamma)),
  
  mean_est = c(
    unname(fit_sc_norm$estimate["mean"]),
    exp(fit_sc_logn$estimate["meanlog"] + 0.5*fit_sc_logn$estimate["sdlog"]^2),
    unname(fit_sc_gamma$estimate["shape"] / fit_sc_gamma$estimate["rate"])),
  
  sd_est   = c(
    unname(fit_sc_norm$estimate["sd"]),
    sqrt((exp(fit_sc_logn$estimate["sdlog"]^2) - 1) *
           exp(2*fit_sc_logn$estimate["meanlog"] + fit_sc_logn$estimate["sdlog"]^2)),
    sqrt(unname(fit_sc_gamma$estimate["shape"]) / (unname(fit_sc_gamma$estimate["rate"])^2))))

# Flinders Street
fl <- pedestrian_df$flinders_street
fit_fl_norm  <- fitdistr(fl, "normal")
fit_fl_logn  <- fitdistr(fl, "lognormal")
fit_fl_gamma <- fitdistr(fl, "gamma")

fl_models <- tibble(
  crossing = "Flinders Street",
  model    = c("normal","lognormal","gamma"),
  logLik   = c(logLik(fit_fl_norm)[1],  logLik(fit_fl_logn)[1],  logLik(fit_fl_gamma)[1]),
  AIC      = c(AIC(fit_fl_norm),        AIC(fit_fl_logn),        AIC(fit_fl_gamma)),
  
  mean_est = c(
    unname(fit_fl_norm$estimate["mean"]),
    exp(fit_fl_logn$estimate["meanlog"] + 0.5*fit_fl_logn$estimate["sdlog"]^2),
    unname(fit_fl_gamma$estimate["shape"] / fit_fl_gamma$estimate["rate"])),
  
  sd_est   = c(
    unname(fit_fl_norm$estimate["sd"]),
    sqrt((exp(fit_fl_logn$estimate["sdlog"]^2) - 1) *
           exp(2*fit_fl_logn$estimate["meanlog"] + fit_fl_logn$estimate["sdlog"]^2)),
    sqrt(unname(fit_fl_gamma$estimate["shape"]) / (unname(fit_fl_gamma$estimate["rate"])^2))))

# QV Melbourne
qv <- pedestrian_df$qv_melbourne
fit_qv_norm  <- fitdistr(qv, "normal")
fit_qv_logn  <- fitdistr(qv, "lognormal")
fit_qv_gamma <- fitdistr(qv, "gamma")

qv_models <- tibble(
  crossing = "QV Melbourne",
  model    = c("normal","lognormal","gamma"),
  logLik   = c(logLik(fit_qv_norm)[1],  logLik(fit_qv_logn)[1],  logLik(fit_qv_gamma)[1]),
  AIC      = c(AIC(fit_qv_norm),        AIC(fit_qv_logn),        AIC(fit_qv_gamma)),
  
  mean_est = c(
    unname(fit_qv_norm$estimate["mean"]),
    exp(fit_qv_logn$estimate["meanlog"] + 0.5*fit_qv_logn$estimate["sdlog"]^2),
    unname(fit_qv_gamma$estimate["shape"] / fit_qv_gamma$estimate["rate"])),
  
  sd_est   = c(
    unname(fit_qv_norm$estimate["sd"]),
    sqrt((exp(fit_qv_logn$estimate["sdlog"]^2) - 1) *
           exp(2*fit_qv_logn$estimate["meanlog"] + fit_qv_logn$estimate["sdlog"]^2)),
    sqrt(unname(fit_qv_gamma$estimate["shape"]) / (unname(fit_qv_gamma$estimate["rate"])^2))))

mle_fits <- bind_rows(sc_models, fl_models, qv_models) %>%
  arrange(crossing, AIC)

mle_fits  %>%
  kable(
    col.names = c("Crossing", "Model", "Log-Likelihood", "AIC", "Mean Estimate", "SD Estimate"),
    digits = 1,
    align = rep("c")) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center") %>%
  row_spec(0, bold = TRUE, color = "#FFFFFF", background = "#598392") %>%
  column_spec(1, bold = TRUE, color = "#004D40")
```

To validate these choices visually, I used QQ plots.

```{r, echo=FALSE}
#| label: fig-qqplots
#| fig-cap: "QQ plots comparing empirical and theoretical quantiles for the fitted Normal, Lognormal and Gamma models at each crossing."
#| warning: false

par(mfrow = c(1,3), mar = c(4,4,2,1))

## Southern Cross 
x <- sort(sc); n <- length(x); p <- (seq_len(n) - 0.5) / n
qN <- qnorm(p,  mean = fit_sc_norm$estimate["mean"],    sd = fit_sc_norm$estimate["sd"])
qL <- qlnorm(p, meanlog = fit_sc_logn$estimate["meanlog"], sdlog = fit_sc_logn$estimate["sdlog"])
qG <- qgamma(p, shape = fit_sc_gamma$estimate["shape"], rate = fit_sc_gamma$estimate["rate"])

plot(qN, x, xlab = "Theoretical quantiles", ylab = "Empirical quantiles",
     main = "Southern Cross", pch = 16, col = "#8F250C", cex = 0.8)
points(qL, x, pch = 16, col = "#9cb380", cex = 0.8)
points(qG, x, pch = 16, col = "#124559", cex = 0.8)
abline(0, 1, lty = 2)
legend("topleft", legend = c("Normal", "Lognormal", "Gamma"),
       col = c("#8F250C", "#9cb380", "#124559"), pch = 16, bty = "n", cex = 0.8)

# Flinders Street
x <- sort(fl); n <- length(x); p <- (seq_len(n) - 0.5) / n
qN <- qnorm(p,  mean = fit_fl_norm$estimate["mean"],    sd = fit_fl_norm$estimate["sd"])
qL <- qlnorm(p, meanlog = fit_fl_logn$estimate["meanlog"], sdlog = fit_fl_logn$estimate["sdlog"])
qG <- qgamma(p, shape = fit_fl_gamma$estimate["shape"], rate = fit_fl_gamma$estimate["rate"])

plot(qN, x, xlab = "Theoretical quantiles", ylab = "Empirical quantiles",
     main = "Flinders Street", pch = 16, col = "#8F250C", cex = 0.8)
points(qL, x, pch = 16, col = "#9cb380", cex = 0.8)
points(qG, x, pch = 16, col = "#124559", cex = 0.8)
abline(0, 1, lty = 2)

# QV Melbourne 
x <- sort(qv); n <- length(x); p <- (seq_len(n) - 0.5) / n
qN <- qnorm(p,  mean = fit_qv_norm$estimate["mean"],    sd = fit_qv_norm$estimate["sd"])
qL <- qlnorm(p, meanlog = fit_qv_logn$estimate["meanlog"], sdlog = fit_qv_logn$estimate["sdlog"])
qG <- qgamma(p, shape = fit_qv_gamma$estimate["shape"], rate = fit_qv_gamma$estimate["rate"])

plot(qN, x, xlab = "Theoretical quantiles", ylab = "Empirical quantiles",
     main = "QV Melbourne", pch = 16, col = "#8F250C", cex = 0.8)
points(qL, x, pch = 16, col = "#9cb380", cex = 0.8)
points(qG, x, pch = 16, col = "#124559", cex = 0.8)
abline(0, 1, lty = 2)

```

The results made sense intuitively. Southern Cross behaves in a more symmetric way so the Normal model works there. Flinders Street and QV Melbourne are right skewed so the Lognormal model captures their structure better. These choices become important later once we start estimating upper percentiles and running simulations.

## Understanding the Busiest Days
Planners often care about the 90th percentile flow. It is the level of traffic that only occurs on the busiest one out of ten days. If a crossing struggles at this level it gets congested.

To estimate this level, I used both:

- direct quantiles from the sample
- bootstrap confidence intervals
- model based percentile estimates

The bootstrap method shows how the estimate varies if the data were resampled repeatedly.

```{r, echo=FALSE}
#| label: tbl-q90-sample
#| tbl-cap: "Empirical 90th percentile estimates and 95% bootstrap confidence intervals for each crossing"

pedestrian_long %>%
  group_by(crossing) %>%
  summarise(q90 = quantile(count, 0.9)) %>%
  kable(
        digits = 1, align = c("l","r")) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE) %>%
  row_spec(0, bold = TRUE, color = "#FFFFFF", background = "#598392") %>%
  column_spec(1, bold = TRUE, color = "#004D40")
  
q90_fn <- function(data, i) quantile(data[i], 0.9)

# Flinders Street
fl_boot <- boot(pedestrian_df$flinders_street, q90_fn, R = 1000)
ci_fl <- boot.ci(fl_boot, type = "perc")

# Southern Cross
sc_boot <- boot(pedestrian_df$southern_cross, q90_fn, R = 1000)
ci_sc <- boot.ci(sc_boot, type = "perc")

# QV Melbourne
qv_boot <- boot(pedestrian_df$qv_melbourne, q90_fn, R = 1000)
ci_qv <- boot.ci(qv_boot, type = "perc")

sample_tbl <- tibble(
  crossing = c("Flinders Street","Southern Cross","QV Melbourne"),
  q90_sample = round(c(
    quantile(pedestrian_df$flinders_street, 0.9),
    quantile(pedestrian_df$southern_cross, 0.9),
    quantile(pedestrian_df$qv_melbourne, 0.9)), 
    2),
  q90_sample_low  = round(c(ci_fl$percent[4], ci_sc$percent[4], ci_qv$percent[4]), 2),
  q90_sample_high = round(c(ci_fl$percent[5], ci_sc$percent[5], ci_qv$percent[5]), 2))

```

Then I used the model fits to estimate theoretical percentiles and confidence intervals.

```{r, echo=FALSE}
#| label: tbl-q90-final
#| tbl-cap: "Comparison of empirical and model-based 90th percentile estimates with 95% confidence intervals for each crossing"

q90_model_point <- list(
  fl = qlnorm(0.9, meanlog = fit_fl_logn$estimate["meanlog"], sdlog = fit_fl_logn$estimate["sdlog"]),
  sc = qnorm (0.9, mean    = fit_sc_norm$estimate["mean"],     sd    = fit_sc_norm$estimate["sd"]),
  qv = qlnorm(0.9, meanlog = fit_qv_logn$estimate["meanlog"], sdlog = fit_qv_logn$estimate["sdlog"]))

q90_model_ci <- function(fit, dist, n, B = 1000) {
  boot_q90 <- replicate(B, {
    sim <- if (dist == "normal") {
      rnorm(n, mean = fit$estimate["mean"], sd = fit$estimate["sd"])}
    else {
      rlnorm(n, meanlog = fit$estimate["meanlog"], sdlog = fit$estimate["sdlog"])}
    quantile(sim, 0.9)})
  quantile(boot_q90, c(0.025, 0.975))}

n_fl <- nrow(pedestrian_df)
n_sc <- nrow(pedestrian_df)
n_qv <- nrow(pedestrian_df)

ci_fl_m <- q90_model_ci(fit_fl_logn, "lognormal", n_fl)
ci_sc_m <- q90_model_ci(fit_sc_norm, "normal", n_sc)
ci_qv_m <- q90_model_ci(fit_qv_logn, "lognormal", n_qv)

model_tbl <- tibble(
  crossing       = c("Flinders Street","Southern Cross","QV Melbourne"),
  model          = c("lognormal","normal","lognormal"),
  q90_model      = round(c(q90_model_point$fl, q90_model_point$sc, q90_model_point$qv), 2),
  q90_model_low  = round(c(ci_fl_m[1], ci_sc_m[1], ci_qv_m[1]), 2),
  q90_model_high = round(c(ci_fl_m[2], ci_sc_m[2], ci_qv_m[2]), 2))

final_tbl <- sample_tbl %>%
  left_join(model_tbl, by = "crossing")

final_tbl %>%
  kable(
    digits = 1,
    align = rep("c", ncol(.))) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center") %>%
  row_spec(0, bold = TRUE, color = "#FFFFFF", background = "#598392") %>%
  column_spec(1, bold = TRUE, color = "#004D40")

```

The interesting part is that both approaches lined up almost perfectly. That gave confidence that the models were capturing the behaviour well. QV Melbourne showed a very high threshold, well above 2600. Southern Cross and Flinders Street sat around the 900 to 1000 mark.

## Are Two Crossings Similar Enough for a Shared Design?
At one stage the engineering question was straightforward. If Southern Cross and Flinders Street differed by more than 80 people per hour on average, they would need separate designs.

A paired t test gave a clear answer.

```{r, echo=FALSE}
#| label: tbl-t-test
#| tbl-cap: "Paired t-test results comparing Southern Cross and Flinders Street (95% confidence interval for mean difference)."

df  <- na.omit(pedestrian_df[, c("southern_cross","flinders_street")])
sc  <- df$southern_cross
fl  <- df$flinders_street
d   <- sc - fl                 

tt <- t.test(sc, fl, paired = TRUE, conf.level = 0.95)
paired_tt_tbl <- tibble(
  Comparison = "Southern Cross âˆ’ Flinders Street",
  Mean_Diff  = tt$estimate,
  `95% CI (Low)` = tt$conf.int[1],
  `95% CI (High)` = tt$conf.int[2],
  t_value = tt$statistic,
  df = tt$parameter,
  p_value = tt$p.value)

paired_tt_tbl %>%
  kable(
    digits = 2,
    align = rep("c", ncol(.))) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center") %>%
  row_spec(0, bold = TRUE, color = "#FFFFFF", background = "#598392") %>%
  column_spec(1, bold = TRUE, color = "#004D40")

```

I checked the normality of differences.

```{r, echo=FALSE}
#| label: fig-qq-differences
#| fig-cap: "QQ plot of paired differences (Southern Cross - Flinders Street) showing approximate normality."

qqnorm(scale(d),
       main = "QQ of differences: Southern Cross âˆ’ Flinders",
       pch  = 16,
       col  = adjustcolor("#3a405a", alpha.f = 0.5))

qqline(scale(d),
       col  = "#598392",
       lwd  = 2,
       lty  = 2)
```

Then illustrated the estimate and confidence interval.

```{r, echo=FALSE}
#| label: fig-ci
#| fig-cap: "95% confidence interval for the mean difference between Southern Cross and Flinders Street. Shaded area shows +-80 people/hour design tolerance."
#| subtitle: "Shaded zone = +-80 people/hour (design tolerance)"

ci <- tibble(
  estimate = tt$estimate,
  lower = tt$conf.int[1],
  upper = tt$conf.int[2])

ggplot(ci) +
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = -80, ymax = 80),
            fill = "#b5cda3", alpha = 0.2) +
  geom_errorbar(aes(x = 1, ymin = lower, ymax = upper),
                width = 0.08, linewidth = 1,
                colour = "#3a405a") +
  geom_point(aes(x = 1, y = estimate),
             size = 3, colour = "#124559") +
  geom_hline(yintercept = 0, linetype = "dashed", colour = "#444444") +
  coord_cartesian(ylim = c(-120, 120)) +
  scale_x_continuous(limits = c(0.5, 1.5), breaks = NULL) +
  labs(
    y = "Difference in mean counts (SC-FL)",
    x = NULL) +
  theme_minimal(base_size = 13)

```

The confidence interval stayed below 80. This means the two locations are similar enough to share the same physical design. It is a simple result but it has real engineering implications and potential cost savings.

## Which Location Offers the Best Marketing Opportunity?
Pedestrian flow directly relates to advertising value. To compare locations fairly, I estimated the mean counts and their confidence intervals.

```{r, results='hide', task4_tt, echo=FALSE}
# Southern Cross
tt_sc <- t.test(pedestrian_df$southern_cross, conf.level = 0.95)

# Flinders Street
tt_fl <- t.test(pedestrian_df$flinders_street, conf.level = 0.95)

# QV
tt_qv <- t.test(pedestrian_df$qv, conf.level = 0.95)
```

```{r}
#| label: tbl-task4-ttest
#| tbl-cap: "Mean pedestrian counts and 95% confidence intervals for each crossing (one-sample t-tests)"

tt_table <- tibble(
  Location = c("Southern Cross", "Flinders Street", "QV Melbourne"),
  Mean     = c(tt_sc$estimate, tt_fl$estimate, tt_qv$estimate),
  `95% CI (Low)`  = c(tt_sc$conf.int[1], tt_fl$conf.int[1], tt_qv$conf.int[1]),
  `95% CI (High)` = c(tt_sc$conf.int[2], tt_fl$conf.int[2], tt_qv$conf.int[2]))

tt_table %>%
  kable(
    digits = 1,
    align = rep("c", ncol(.))) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center") %>%
  row_spec(0, bold = TRUE, color = "#FFFFFF", background = "#598392") %>%
  column_spec(1, bold = TRUE, color = "#004D40")
```

A lollipop chart showed the contrasts clearly.

```{r, echo=FALSE}
#| label: fig-task4-traffic
#| fig-cap: "Pedestrian Traffic with 95% Confidence Intervals"

ggplot(tt_table, aes(x = Location, y = Mean, color = Location)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymin = `95% CI (Low)`, ymax = `95% CI (High)`), width = 0.15, linewidth = 1) +
  geom_segment(aes(xend = Location, y = 0, yend = Mean), color = "grey80") +
  scale_color_manual(values = cross_cols) +
  labs(
    y = "Mean pedestrians per hour",
    x = "Location") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")

```

QV Melbourne stands out strongly again. It is not only busy but consistently busy. Southern Cross and Flinders Street are steady but sit at roughly half the mean of QV.

## Estimating Billboard Revenue

One final practical question emerged. If a bank paid a base amount plus a bonus depending on how often a site exceeded 1000 people per hour, which crossing would earn the most?

I calculated the proportion of days above that threshold using Wilson confidence intervals.
```{r}
#| label: tbl-task5-revenue
#| tbl-cap: "Estimated expected revenue and 95% confidence intervals for each crossing using the Wilson score interval."

THRESH  <- 1000
BASE    <- 10000
BONUS   <- 5000
LEVEL   <- 0.95

# Binomial proportion + Wilson CI
rev_ci <- pedestrian_long %>%
  mutate(over_1000 = count > THRESH) %>%
  group_by(crossing) %>%
  summarise(
    n = n(),
    k = sum(over_1000),
    .groups = "drop") %>%
  rowwise() %>%
  mutate(
    pt   = list(prop.test(k, n, conf.level = LEVEL, correct = TRUE)),
    phat = pt$estimate[[1]],
    lo_p = pt$conf.int[1],
    hi_p = pt$conf.int[2],
    rev_hat = BASE + BONUS * phat,
    rev_lo  = BASE + BONUS * lo_p,
    rev_hi  = BASE + BONUS * hi_p) %>%
  ungroup() 

rev_ci <- rev_ci[, c("crossing","n", "k", "phat", "lo_p", "hi_p", "rev_hat", "rev_lo", "rev_hi")]

rev_ci %>%
  kable(
    col.names = c("Crossing", "n", "k", "Proportion >1000", "CI (Low)", "CI (High)", "Estimated Revenue", "Revenue CI (Low)", "Revenue CI (High)"),
    digits = 1,
    align = rep("c", ncol(.))) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center") %>%
  row_spec(0, bold = TRUE, color = "#FFFFFF", background = "#598392") %>%
  column_spec(1, bold = TRUE, color = "#004D40")
```

And visualised the result.

```{r, echo=FALSE}
#| label: fig-task5-revenue
#| fig-cap: "Expected billboard revenue with 95% confidence intervals at each crossing."

ggplot(rev_ci, aes(x = reorder(crossing, rev_hat), y = rev_hat)) +
  geom_col(aes(fill = crossing), width = 0.6) +
  geom_errorbar(aes(ymin = rev_lo, ymax = rev_hi), width = 0.2) +
  geom_text(aes(label = dollar(rev_hat, accuracy = 1)),
            vjust = -0.5, size = 3.5) +
  scale_fill_manual(values = cross_cols) +
  scale_y_continuous(
    labels = label_dollar(prefix = "$", accuracy = 1),
    expand = expansion(mult = c(0, 0.08))) +
  coord_flip() +
  labs(
    x = NULL, y = "Expected revenue") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none")
```

QV Melbourne once again delivered the highest and most reliable revenue because it exceeded the threshold every single day in the dataset. Flinders Street and Southern Cross showed lower and similar values.

## Final Thoughts

What started as a simple exploration turned into a deeper look at how Melbourne moves. Each crossing behaves differently and those differences matter. They influence engineering decisions, marketing opportunities, and even the reliability of revenue estimates.

Southern Cross is steady. Flinders Street is slightly lower but similar in structure. QV Melbourne is on its own path with heavy traffic and large fluctuations that give it both challenges and commercial potential.
Data lets us see these places as more than busy intersections. They become systems with measurable behaviour and predictable characteristics. That is what makes this type of analysis rewarding. It connects statistical modelling to real city life.

###  Code and Reproducibility

::: {.callout-tip collapse="true" title="Click to View Full Code and Data"}
Full datasets, scripts, and the original group project are available here:

- Group source code: <https://github.com/jyovika/Pedestrian_Crossings_Data_Analysis>  
- My analytics portfolio repository: <https://github.com/jyovika/jyovika-analytics-portfolio>
:::



